{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LIT in Notebooks",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2c6PyqQaNiA"
      },
      "source": [
        "# Using the Language Interpretability Tool in Notebooks\n",
        "\n",
        "This notebook shows use of the [Language Interpretability Tool](https://pair-code.github.io/lit) on a binary classifier for labelling statement sentiment (0 for negative, 1 for positive).\n",
        "\n",
        "The LitWidget object constructor takes a dict mapping model names to model objects, and a dict mapping dataset names to dataset objects. Those will be the datasets and models displayed in LIT. It also optionally takes in a `height` parameter for how tall to render the LIT UI in pixels (it defaults to 1000 pixels). Running the constructor will cause the LIT server to be started in the background, loading the models and datasets and enabling the UI to be served.\n",
        "\n",
        "Render the LIT UI in an output cell by calling the `render` method on the LitWidget object. The LIT UI can be rendered multiple times in separate cells if desired. The widget also contains a `stop` method to shut down the LIT server.\n",
        "\n",
        "Copyright 2020 Google LLC.\n",
        "SPDX-License-Identifier: Apache-2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukXamAB_FBM8"
      },
      "source": [
        "# Install LIT and transformers packages. The transformers package is needed by the model and dataset we are using.\n",
        "!pip install lit_nlp\n",
        "!pip install transformers==2.11.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30l9ZyTjxJjf"
      },
      "source": [
        "# Fetch the trained model weights\n",
        "!wget https://storage.googleapis.com/what-if-tool-resources/lit-models/sst2_tiny.tar.gz\n",
        "!tar -xvf sst2_tiny.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWhbAZg57RpB"
      },
      "source": [
        "# Create the LIT widget with the model and dataset to analyze.\n",
        "from lit_nlp import notebook\n",
        "from lit_nlp.examples.datasets import glue\n",
        "from lit_nlp.examples.models import glue_models\n",
        "\n",
        "datasets = {'sst_dev': glue.SST2Data('validation')}\n",
        "models = {'sst_tiny': glue_models.SST2Model('./')}\n",
        "\n",
        "widget = notebook.LitWidget(models, datasets, height=800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GSfs1waBdLd"
      },
      "source": [
        "# Render the widget\n",
        "widget.render()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}